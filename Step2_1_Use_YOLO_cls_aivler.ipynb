{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyurDtxqHT0o"
      },
      "source": [
        "# **Use YOLO-cls !**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE6nWiH8-i9q"
      },
      "source": [
        "## 0.미션\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53bSTpVT-n_Y"
      },
      "source": [
        "### (1) 미션1\n",
        "여러분은 노트북에서 얼굴 인식 파일을 실행시키기 위해 **문제에 적합한** UltraLytics YOLO-cls 모델을 만들어야 합니다.\n",
        "\n",
        "그 전에 가지고 있는 데이터셋을 **학습에 적합한 형태**로 바꿔야 합니다.\n",
        "\n",
        "- 1) 데이터셋을 불러옵니다.\n",
        "    - 데이터셋은 2가지입니다. 본인의 얼굴 이미지 파일, 다른 사람의 얼굴 이미지 파일.\n",
        "- 2) 데이터셋을 전처리합니다.\n",
        "    - UltraLytics YOLO-cls 모델에서 요구하는 데이터셋 폴더의 구조가 있습니다.\n",
        "    - [UltraLytics YOLO-cls 모델의 데이터셋 구조 링크](https://docs.ultralytics.com/datasets/classify/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBjsZP8C-2Ra"
      },
      "source": [
        "### (2) 미션2\n",
        "데이터셋의 폴더 구조를 **학습에 적합한 형태**로 만들었다면, **사전 학습된 UltraLytics YOLO-cls 모델**에 Transfer Learning을 수행합니다.\n",
        "\n",
        "- 1) UltraLytics YOLO-cls 모델 선택\n",
        "    - 세부 모델로 n, s, m, l, x가 있습니다. n가 가장 빠르고, x가 가장 연산량이 많습니다.\n",
        "    - [UltraLytics YOLO-cls 모델 링크](https://docs.ultralytics.com/tasks/classify/)\n",
        "- 2) 선택한 UltraLytics YOLO-cls 모델로 학습을 진행합니다.\n",
        "    - [UltraLytics YOLO 학습 명령어 링크](https://docs.ultralytics.com/modes/train/#train-settings)\n",
        "- 3) 학습이 완료되면 추론을 진행합니다.\n",
        "    - [UltraLytics YOLO 추론 명령어 링크](https://docs.ultralytics.com/modes/predict/#inference-arguments)\n",
        "- 4) 해당 UltraLytics YOLO-cls 모델을 **반드시** 저장합니다.\n",
        "    - 모델을 **반드시** 저장하세요.\n",
        "    - .pt 형태로 Colab에 저장이 될 것입니다. 해당 파일을 **로컬에 다운로드** 하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkDv7UfdYOgg"
      },
      "source": [
        "## 1.환경설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIxbiQ8wYOcy"
      },
      "source": [
        "* 세부 요구사항\n",
        "    - 경로 설정 : 구글콜랩\n",
        "        * 구글 드라이브 바로 밑에 project4 폴더를 만드세요.\n",
        "        * 데이터 파일을 복사해 넣습니다.\n",
        "        * 필요하다고 판단되는 라이브러리를 추가하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIjpXC-xYHh3"
      },
      "source": [
        "### (1) 경로 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6qgvZMSYcoX"
      },
      "source": [
        "* 구글 드라이브 연결"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "imfft4dGGJ2E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6899ea70-3260-4c58-abb7-4cbd0f11e09a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WPngJ_nwZPRC"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/project4'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNEKwf_LY0JB"
      },
      "source": [
        "### (2) 라이브러리 설치 및 불러오기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPwDW6e_Y0Fa"
      },
      "source": [
        "* 라이브러리 로딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "a4dS7tW-Zwrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fa1f74a-5d75-4844-8c56-d17301c9879a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.26-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.10-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.26-py3-none-any.whl (878 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m879.0/879.0 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.10-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.26 ultralytics-thop-2.0.10\n"
          ]
        }
      ],
      "source": [
        "## colab에서 세션 재시작을 요구하는 팝업이 뜨면 재시작 누르세요.\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eg0gCl9Yatak"
      },
      "source": [
        "## 2.미션1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPvTHwTmbKR5"
      },
      "source": [
        "여러분은 노트북에서 얼굴 인식 파일을 실행시키기 위해 **문제에 적합한** UltraLytics YOLO-cls 모델을 만들어야 합니다.\n",
        "\n",
        "그 전에 가지고 있는 데이터셋을 **학습에 적합한 형태**로 바꿔야 합니다.\n",
        "\n",
        "- 1) 데이터셋을 불러옵니다.\n",
        "    - 데이터셋은 2가지입니다. 본인의 얼굴 이미지 파일, 다른 사람의 얼굴 이미지 파일.\n",
        "- 2) 데이터셋을 전처리합니다.\n",
        "    - UltraLytics YOLO-cls 모델에서 요구하는 데이터셋 폴더의 구조가 있습니다.\n",
        "    - [UltraLytics YOLO-cls 모델의 데이터셋 구조 링크](https://docs.ultralytics.com/datasets/classify/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rXSONrsatd5"
      },
      "source": [
        "### (1) 데이터셋 불러오기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXLqxwNaathI"
      },
      "source": [
        "* **세부 요구사항**\n",
        "    - 데이터셋을 불러옵니다.\n",
        "        - 데이터셋은 두 개의 압축 파일이어야 합니다.\n",
        "            1. lfw-deepfunneled.zip : Labeled Faces in the Wild 데이터셋\n",
        "                - 압축 파일을 로컬에 다운로드 받아서 **어떤 구조**인지 확인하세요.\n",
        "            2. 여러분의 얼굴 이미지 데이터셋\n",
        "                - 여러분의 얼굴 이미지가 담긴 **압축 파일**을 **Google Drive에 업로드** 하기를 권장합니다.\n",
        "                    - 이미지 파일 하나하나 업로드 하면 시간이 오래 걸립니다.\n",
        "    - 데이터셋 압축 파일을 **Colab에 폴더를 생성한 후 해제**하세요.\n",
        "        - 데이터셋 폴더를 **본인 얼굴 폴더, LFW 폴더로 나누어** 생성하는 것을 권장합니다.\n",
        "        - 만일 두 압축 파일을 하나의 폴더에 모두 해제하면 전처리가 더 까다로워질 것입니다.\n",
        "    - 예시 코드에서 사용한 라이브러리\n",
        "        - os, zipfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OntGw5H-C3q"
      },
      "source": [
        "#### 1) 본인 얼굴 이미지 데이터셋 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "v29VprrhqFO7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bFq5L4aAeQHr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e38625ce-15b8-48d4-d11d-362838c81dbb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/project4/myface_exam.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data_myFace = os.path.join(path, '/content/drive/MyDrive/project4/myface_exam.zip')\n",
        "data_myFace"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Colab에 생성할 본인 얼굴 폴더 경로\n",
        "extract_folder = '/content/my_face'\n",
        "\n",
        "## 위의 경로에 폴더가 없을 때 생성\n",
        "if not os.path.exists(extract_folder) :\n",
        "    os.makedirs(extract_folder)\n",
        "\n",
        "## 위의 경로에 압축을 해제\n",
        "with zipfile.ZipFile(data_myFace, 'r') as zip_ref :\n",
        "    file_list = zip_ref.namelist()\n",
        "\n",
        "    for f in file_list :\n",
        "        if not f.endswith('/') and f.lower().endswith('.jpg') :\n",
        "            file_name = os.path.basename(f)\n",
        "\n",
        "            if not file_name.startswith('._') :\n",
        "                d_path = os.path.join(extract_folder, file_name)\n",
        "\n",
        "                with zip_ref.open(f) as source, open(d_path, 'wb') as target :\n",
        "                    target.write(source.read())"
      ],
      "metadata": {
        "id": "6YRl75_KqL6q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rITP9F5qeQ5K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45ac1d0e-bd24-4df2-9b7f-3a7f8bc60b71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5999"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(os.listdir(extract_folder) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCDldok5ySsg"
      },
      "source": [
        "#### 2) 다른 얼굴 이미지 데이터셋 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NTzgG1M1eR-A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9c97be6a-4e33-432a-e3da-3e474a55b69a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/project4/Datasets/Keras/lfw-deepfunneled.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data_other = '/content/drive/MyDrive/project4/Datasets/Keras/lfw-deepfunneled.zip'\n",
        "data_other"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Colab에 생성할 다른 얼굴 폴더 경로\n",
        "extract_folder = '/content/other_face'\n",
        "\n",
        "## 위의 경로에 폴더가 없을 때 생성\n",
        "if not os.path.exists(extract_folder) :\n",
        "    os.makedirs(extract_folder)\n",
        "\n",
        "## 위의 경로에 압축을 해제\n",
        "with zipfile.ZipFile(data_other, 'r') as zip_ref :\n",
        "    file_list = zip_ref.namelist()\n",
        "\n",
        "    for f in file_list :\n",
        "        if not f.endswith('/') and f.lower().endswith('.jpg') :\n",
        "            file_name = os.path.basename(f)\n",
        "\n",
        "            if not file_name.startswith('._') :\n",
        "                d_path = os.path.join(extract_folder, file_name)\n",
        "\n",
        "                with zip_ref.open(f) as source, open(d_path, 'wb') as target :\n",
        "                    target.write(source.read())"
      ],
      "metadata": {
        "id": "LOJvda80qaQq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(extract_folder) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcQmb6jhqaIC",
        "outputId": "606fb287-ec51-4b08-d069-db4c668034d4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13233"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-TovD9FLCCL"
      },
      "source": [
        "### (2) 데이터셋 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJPBtHv8LCCL"
      },
      "source": [
        "* **세부 요구사항**\n",
        "    - 데이터셋을 전처리 합니다.\n",
        "        - YOLO-cls 모델이 요구하는 폴더 구조를 만듭니다.\n",
        "            1. Datasets라는 폴더를 생성합니다.\n",
        "            2. Training set, Validation set, Test set(선택 사항) 각 데이터셋이 들어갈 폴더를 생성합니다.\n",
        "            3. 각 데이터셋 폴더에 분류할 클래스의 이름을 가진 폴더를 생성합니다.\n",
        "        - 폴더 구조에 맞게 데이터를 분배합니다.\n",
        "    - 예시 코드에서 사용한 라이브러리\n",
        "        - os, glob, random, shutil, numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_MF4zCRie5X"
      },
      "source": [
        "#### 1) 모델이 요하는 구조의 폴더 생성"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "r_An_zZsWizq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 각 데이터셋 길이 비교\n",
        "len(os.listdir('/content/my_face')) , len(os.listdir('/content/other_face'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L26fF1sqWj8u",
        "outputId": "02a9cb25-d97d-4e93-e9db-dd9ee15ef2dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5999, 13233)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 폴더 생성\n",
        "datasets_path = '/content/Datasets'\n",
        "\n",
        "## 원본 폴더 경로들\n",
        "source_folders = {\n",
        "    'my_face': '/content/my_face',\n",
        "    'other_face': '/content/other_face'\n",
        "}\n",
        "\n",
        "## 타겟 폴더 경로들\n",
        "target_folders = {\n",
        "    'train': {'my_face': '/content/Datasets/train/my_face',\n",
        "              'other_face': '/content/Datasets/train/other_face',\n",
        "              },\n",
        "    'val': {'my_face': '/content/Datasets/val/my_face',\n",
        "            'other_face': '/content/Datasets/val/other_face',\n",
        "            },\n",
        "    }\n",
        "\n",
        "## 폴더 생성\n",
        "if not os.path.exists(datasets_path) :\n",
        "    os.mkdir(datasets_path)\n",
        "\n",
        "## 하위 폴더 생성\n",
        "for folder in target_folders :\n",
        "    temp1 = os.path.join(datasets_path , folder)\n",
        "    if not os.path.exists( temp1 ) :\n",
        "        os.mkdir( temp1 )\n",
        "\n",
        "    for folder2 in source_folders.keys() :\n",
        "        temp2 = os.path.join(temp1, folder2)\n",
        "        if not os.path.exists( temp2 ) :\n",
        "            os.mkdir( temp2 )"
      ],
      "metadata": {
        "id": "Nlq_6-c0WpDE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZPds1GraeJ3"
      },
      "source": [
        "#### 2) 각 폴더에 이미지 데이터 옮기기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 스플릿 비율\n",
        "split_size = 0.8\n",
        "\n",
        "## 각 카테고리(my_face, other_face)에 대해 처리\n",
        "for category, source_folder in source_folders.items():\n",
        "    ## 원본 폴더에서 모든 파일 리스트 가져오기\n",
        "    ## 데이터 불균형을 막기 위해 11000장만 사용\n",
        "    img_list = sorted(glob.glob(os.path.join(source_folder, '*')))[:6000]\n",
        "\n",
        "    ## 총 파일 개수 계산\n",
        "    total_imgs = len(img_list)\n",
        "    tr_val_split = int(total_imgs * split_size)\n",
        "\n",
        "    ## train, validation, test로 나누기\n",
        "    tr_img = img_list[ : tr_val_split]\n",
        "    val_img = img_list[tr_val_split : ]\n",
        "\n",
        "    ## 각각의 이미지들을 타겟 폴더로 이동\n",
        "    for img_path in tr_img :\n",
        "        dst_path = os.path.join(target_folders['train'][category], os.path.basename(img_path))\n",
        "        shutil.move(img_path , dst_path)\n",
        "\n",
        "    for img_path in val_img :\n",
        "        dst_path = os.path.join(target_folders['val'][category], os.path.basename(img_path))\n",
        "        shutil.move(img_path , dst_path)\n",
        "\n",
        "    print(f'{category} images moved to train, validation sets')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwYL8PEdXJUL",
        "outputId": "66ed743e-1f31-47b0-dcb8-b3015e15fbba"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my_face images moved to train, validation sets\n",
            "other_face images moved to train, validation sets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( len(os.listdir('/content/Datasets/train/my_face') ) )\n",
        "print( len(os.listdir('/content/Datasets/train/other_face') ) )\n",
        "\n",
        "print( len(os.listdir('/content/Datasets/val/my_face') ) )\n",
        "print( len(os.listdir('/content/Datasets/val/other_face') ) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsS9ao0YXZ-j",
        "outputId": "b2a2da80-f37f-436e-b284-0e8997965158"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4799\n",
            "4800\n",
            "1200\n",
            "1200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w59u5Dtnrh5h"
      },
      "source": [
        "## 3.미션2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHu91EoOrh2Q"
      },
      "source": [
        "데이터셋의 폴더 구조를 **학습에 적합한 형태**로 만들었다면, **사전 학습된 UltraLytics YOLO-cls 모델**에 Transfer Learning을 수행합니다.\n",
        "\n",
        "- 1) UltraLytics YOLO-cls 모델 선택\n",
        "    - 세부 모델로 n, s, m, l, x가 있습니다. n가 가장 빠르고, x가 가장 연산량이 많습니다.\n",
        "    - [UltraLytics YOLO-cls 모델 링크](https://docs.ultralytics.com/tasks/classify/)\n",
        "- 2) 선택한 UltraLytics YOLO-cls 모델로 학습을 진행합니다.\n",
        "    - [UltraLytics YOLO 학습 명령어 링크](https://docs.ultralytics.com/modes/train/#train-settings)\n",
        "- 3) 학습이 완료되면 추론을 진행합니다.\n",
        "    - [UltraLytics YOLO 추론 명령어 링크](https://docs.ultralytics.com/modes/predict/#inference-arguments)\n",
        "- 4) 해당 UltraLytics YOLO-cls 모델을 **반드시** 저장합니다.\n",
        "    - 모델을 **반드시** 저장하세요.\n",
        "    - .pt 형태로 Colab에 저장이 될 것입니다. 해당 파일을 **로컬에 다운로드** 하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AygPItZba0TI"
      },
      "source": [
        "#### (1) UltraLytics YOLO-cls 모델 선택"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO, settings\n",
        "settings['datasets_dir'] = '/content/'\n",
        "settings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "re0ClAklLkLD",
        "outputId": "11cb26db-ead6-4937-891f-fd650df08807"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'settings_version': '0.0.6',\n",
              " 'datasets_dir': '/content/',\n",
              " 'weights_dir': 'weights',\n",
              " 'runs_dir': 'runs',\n",
              " 'uuid': '569f3ba64b326db489132663f79cd37279811de477381b83ac131e6cdd129cbb',\n",
              " 'sync': True,\n",
              " 'api_key': '',\n",
              " 'openai_api_key': '',\n",
              " 'clearml': True,\n",
              " 'comet': True,\n",
              " 'dvc': True,\n",
              " 'hub': True,\n",
              " 'mlflow': True,\n",
              " 'neptune': True,\n",
              " 'raytune': True,\n",
              " 'tensorboard': True,\n",
              " 'wandb': False,\n",
              " 'vscode_msg': True}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('yolo11n-cls.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU6TZVdZL1Tj",
        "outputId": "006d4e1e-756f-4cf5-ea32-ad0039ccde25"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-cls.pt to 'yolo11n-cls.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.52M/5.52M [00:00<00:00, 101MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7zOy5GfbMTR"
      },
      "source": [
        "* **세부 요구사항**\n",
        "    - 세부 모델로 n, s, m, l, x가 있습니다. n가 가장 빠르고, x가 가장 연산량이 많습니다.\n",
        "    - [UltraLytics YOLO-cls 모델 링크](https://docs.ultralytics.com/tasks/classify/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7rqg7bda6Uz"
      },
      "source": [
        "#### (2) UltraLytics YOLO-cls 모델 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48UKFtS6bc9b"
      },
      "source": [
        "* **세부 요구사항**\n",
        "    - 선택한 UltraLytics YOLO-cls 모델로 학습을 진행합니다.\n",
        "    - [UltraLytics YOLO 학습 명령어 링크](https://docs.ultralytics.com/modes/train/#train-settings)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_tr = model.train(model='/content/yolo11n-cls.pt',\n",
        "                         data='/content/Datasets',\n",
        "                         epochs=10,\n",
        "                         )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm_swdgoYFW6",
        "outputId": "152f2bd1-263b-4a18-980a-6f5256448687"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.26 🚀 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=/content/yolo11n-cls.pt, data=/content/Datasets, epochs=10, time=None, patience=100, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/Datasets/train... found 9599 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/Datasets/val... found 2400 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 10                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLO11n-cls summary: 151 layers, 1,533,666 parameters, 1,533,666 gradients, 3.3 GFLOPs\n",
            "Transferred 234/236 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 87.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Datasets/train... 9599 images, 0 corrupt: 100%|██████████| 9599/9599 [00:02<00:00, 4183.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Datasets/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Datasets/val... 2400 images, 0 corrupt: 100%|██████████| 2400/2400 [00:00<00:00, 2846.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Datasets/val.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 224 train, 224 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/train\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.296G     0.8265         16        224:   1%|          | 6/600 [00:01<01:50,  5.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.296G     0.8254         16        224:   2%|▏         | 13/600 [00:02<01:09,  8.45it/s]\n",
            "100%|██████████| 755k/755k [00:00<00:00, 18.7MB/s]\n",
            "       1/10       0.3G    0.09301         15        224: 100%|██████████| 600/600 [01:25<00:00,  6.98it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 75/75 [00:14<00:00,  5.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10     0.268G   0.002577         15        224: 100%|██████████| 600/600 [01:18<00:00,  7.61it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 75/75 [00:10<00:00,  7.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10     0.268G   0.002198         15        224: 100%|██████████| 600/600 [01:17<00:00,  7.77it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 75/75 [00:10<00:00,  7.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10     0.268G   0.007654         15        224: 100%|██████████| 600/600 [01:20<00:00,  7.44it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 75/75 [00:07<00:00,  9.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10     0.268G   0.004945         15        224: 100%|██████████| 600/600 [01:16<00:00,  7.86it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 75/75 [00:10<00:00,  6.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10     0.268G   0.003406         15        224: 100%|██████████| 600/600 [01:16<00:00,  7.89it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 75/75 [00:14<00:00,  5.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10     0.268G  0.0002448         15        224: 100%|██████████| 600/600 [01:16<00:00,  7.84it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 75/75 [00:07<00:00,  9.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10     0.268G   4.86e-05         15        224: 100%|██████████| 600/600 [01:16<00:00,  7.88it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 75/75 [00:10<00:00,  6.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10     0.268G  9.496e-05         15        224: 100%|██████████| 600/600 [01:19<00:00,  7.54it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 75/75 [00:11<00:00,  6.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.268G  4.289e-05         15        224: 100%|██████████| 600/600 [01:14<00:00,  8.01it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 75/75 [00:07<00:00,  9.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.249 hours.\n",
            "Optimizer stripped from runs/classify/train/weights/last.pt, 3.2MB\n",
            "Optimizer stripped from runs/classify/train/weights/best.pt, 3.2MB\n",
            "\n",
            "Validating runs/classify/train/weights/best.pt...\n",
            "Ultralytics 8.3.26 🚀 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11n-cls summary (fused): 112 layers, 1,528,586 parameters, 0 gradients, 3.2 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/Datasets/train... found 9599 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/Datasets/val... found 2400 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 75/75 [00:11<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n",
            "Speed: 0.1ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_tr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5ahh_A7YQBe",
        "outputId": "343eeb81-f839-47fa-b110-54741bdbe066"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
              "\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7c1d02c76b30>\n",
              "curves: []\n",
              "curves_results: []\n",
              "fitness: 1.0\n",
              "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
              "results_dict: {'metrics/accuracy_top1': 1.0, 'metrics/accuracy_top5': 1.0, 'fitness': 1.0}\n",
              "save_dir: PosixPath('runs/classify/train')\n",
              "speed: {'preprocess': 0.07768481969833374, 'inference': 0.48508455355962116, 'loss': 0.0004066030184427897, 'postprocess': 0.0003773967425028483}\n",
              "task: 'classify'\n",
              "top1: 1.0\n",
              "top5: 1.0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsxBhoAubn2u"
      },
      "source": [
        "#### (3) UltraLytics YOLO-cls 추론"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPtTHcnbbn2u"
      },
      "source": [
        "* **세부 요구사항**\n",
        "    - 학습이 완료되면 추론을 진행합니다.\n",
        "    - [UltraLytics YOLO 추론 명령어 링크](https://docs.ultralytics.com/modes/predict/)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run batched inference on a list of images\n",
        "results = model('/content/Datasets/val/my_face/hs_5317.jpg')  # return a list of Results objects\n",
        "\n",
        "# Process results list\n",
        "for result in results:\n",
        "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
        "    masks = result.masks  # Masks object for segmentation masks outputs\n",
        "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
        "    probs = result.probs  # Probs object for classification outputs\n",
        "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
        "    result.show()  # display to screen\n",
        "    result.save(filename=\"result.jpg\")  # save to disk"
      ],
      "metadata": {
        "id": "gcer_MKccUUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ytKJsOUGhC0"
      },
      "source": [
        "#### (4) UltraLytics YOLO-cls 모델 저장"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkC4WP-8cA7g"
      },
      "source": [
        "* **세부 요구사항**\n",
        "    - 모델을 **반드시** 저장하세요.\n",
        "    - .pt 형태로 Colab에 저장이 될 것입니다. 해당 파일을 **로컬에 다운로드** 하세요."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_check = YOLO('/content/runs/classify/train/weights/best.pt')\n",
        "model_check"
      ],
      "metadata": {
        "id": "OHKWfJ2k2N4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ogDiEgY4chMa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}